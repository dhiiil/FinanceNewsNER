{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = 'file.csv'\n",
    "clean_path = \"./../../data/clean/cleaned_news_unlabeled.txt\"\n",
    "splitted_path = \"./../../data/clean/splitted/\"\n",
    "\n",
    "uncleaned_news=pd.read_csv(\"./../../data/news_unlabeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_capital(text):\n",
    "    \"\"\"\n",
    "    Function to convert upper case word (except abbrevation) in front of sentence into sentence case\n",
    "\n",
    "    Args : Text that you want to convert (str)\n",
    "\n",
    "    Return : Sentence Case (str)\n",
    "    \"\"\"\n",
    "    return re.sub(\n",
    "        r\"^[A-Z]{5,}\\s\",\n",
    "        lambda match: match.group(0).capitalize(),\n",
    "        text,\n",
    "        flags=re.MULTILINE,\n",
    "    )\n",
    "\n",
    "\n",
    "def split_sentences(text):\n",
    "    \"\"\"\n",
    "    Function to split a record that contain more than one sentence\n",
    "\n",
    "    Args : Text that you want to split (str)\n",
    "\n",
    "    Returns : Splitted sentence (list)\n",
    "    \"\"\"\n",
    "    return re.split(r'(?<=\\.)\\s+', text)\n",
    "\n",
    "def preprocessing(data):\n",
    "    \"\"\"\n",
    "    Function to preprocess raw text data for further analysis or model input.\n",
    "\n",
    "    This function performs the following preprocessing steps:\n",
    "        - Change word Dok. into \"Dokumen\"\n",
    "        - Change word \"Plt.\" into \"Plt\"\n",
    "        - Replace the abbrevation yoy into \"secara tahunan\"\n",
    "        - Remove \"(year on year/yoy)\"\n",
    "        - Removes news lead phrases, such as location and source mentions like \"Jakarta, kompas.com -\".\n",
    "        - Remove news lead phrase that contain only city like \"BEIRUT -\", \"JAKARTA -\", & etc.\n",
    "        - Remove numbering in the first sentence\n",
    "        - Remove unwanted leading characters like whitespace, slashes, or hyphens\n",
    "        - Change word \"persen\" into symbol \"%\" (except num word in the beginning sentence)\n",
    "        - Convert upper case word in the beginning of the sentence (another lead news) into sentence case \n",
    "        - Removes any unwanted starting characters like whitespace or slashes.\n",
    "        - Removes certain types of sources or URLs (e.g., \"sumber\" followed by a URL).\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): A DataFrame containing raw text data, specifically in the 'sentence' column.\n",
    "\n",
    "    Returns:\n",
    "        data_cleaned (pandas.DataFrame): A cleaned DataFrame containing the preprocessed text from the 'sentence' column.\n",
    "    \"\"\"\n",
    "    data_cleaned = data.copy()\n",
    "    # Change word Dok. into \"Dokumen\"\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace('Dok.', 'Dokumen')\n",
    "    # Change word \"Plt.\" into \"Plt\"\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace('Plt.', 'Plt')\n",
    "    # Remove \"(year on year/yoy)\"\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace('(year on year/yoy)', '')\n",
    "    # Replace the abbrevation yoy into \"secara tahunan\"\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace('yoy', 'secara tahunan')\n",
    "    # Remove news lead phrase that contain city and source mention\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace(r'(?i)\\b(jakarta\\s+kompas\\.com|kompas\\.com\\s*-|kompas\\.com\\s+|\\bkompas\\.com\\b)\\b', '', regex=True)\n",
    "    # Remove news lead phrase that contain only city\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace(r'^\\w+\\s\\w+\\,\\s+\\-|^\\w+\\,\\s+\\-|^[A-Za-z]+,?\\s+–\\s+', '', regex=True)\n",
    "    # Remove numbering in the first sentence\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace(r'^\\d+\\.\\s*', '', regex=True)\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.lstrip('.')\n",
    "    # Remove unwanted leading characters like whitespace, slashes, or hyphens\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace(r'^[\\s\\-/\\–]+', '', regex=True)\n",
    "    # Change word \"persen\" into symbol \"%\"\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace(r'(?<=\\d)\\s+(persen)', '%', regex=True)\n",
    "    # Remove any sources or URLs following the word \"sumber\" or standalone URLs\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].str.replace(r'\\bsumber\\s+(https?:[^\\s]+|www\\.[^\\s]+)|https?:[^\\s]+|www\\.[^\\s]+', '', regex=True)\n",
    "    # Convert upper case word in the beginning of the sentence into sentence case\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].apply(format_capital)\n",
    "    # Split record that contain more than one sentences\n",
    "    data_cleaned['sentence'] = data_cleaned['sentence'].apply(split_sentences)\n",
    "    # .explode to place the splitted record into another row\n",
    "    data_cleaned = data_cleaned.explode('sentence').reset_index(drop=True)\n",
    "\n",
    "    return data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_news = preprocessing(uncleaned_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pemerintah memperkirakan potensi perputaran uang dari transaksi judi daring (online) bisa mencapai Rp 700 triliun jika langkah intervensi tidak dilakukan.'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_news['sentence'].iloc[1872]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_news['sentence'] = cleaned_news['sentence'].fillna('')\n",
    "cleaned_news['sentence'] = cleaned_news['sentence'][cleaned_news['sentence'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully cleaned and saved in: ./../../data/clean/cleaned_news_unlabeled.txt\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.dirname(clean_path), exist_ok=True)\n",
    "cleaned_news.to_csv(clean_path, index=True)\n",
    "print(f\"File successfully cleaned and saved in: {clean_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan satu kolom ke file .txt menggunakan to_csv\n",
    "cleaned_news[['sentence']].to_csv(clean_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split CSV for labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for kenzie successfully saved in: ./../../data/clean/splitted\\unlabeled_kenzie.csv\n",
      "File for naufal successfully saved in: ./../../data/clean/splitted\\unlabeled_naufal.csv\n",
      "File for hafiz successfully saved in: ./../../data/clean/splitted\\unlabeled_hafiz.csv\n",
      "File for satrio successfully saved in: ./../../data/clean/splitted\\unlabeled_satrio.csv\n"
     ]
    }
   ],
   "source": [
    "split_size = len(cleaned_news) // 4\n",
    "names = ['kenzie', 'naufal', 'hafiz', 'satrio']\n",
    "for i, name in enumerate(names):\n",
    "    start_idx = i * split_size\n",
    "    if i == len(names) - 1:  \n",
    "        end_idx = len(cleaned_news)\n",
    "    else:\n",
    "        end_idx = (i + 1) * split_size\n",
    "    \n",
    "    split_data = cleaned_news.iloc[start_idx:end_idx]\n",
    "    os.makedirs(os.path.dirname(splitted_path), exist_ok=True)\n",
    "    split_file_path = os.path.join(os.path.dirname(splitted_path), f\"unlabeled_{name}.csv\")\n",
    "    split_data.to_csv(split_file_path, index=False)\n",
    "    print(f\"File for {name} successfully saved in: {split_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
